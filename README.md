# VCFAD - Voice Cloning and Fake Audio Detection


## Background:
We are a technology company working in the Cyber Security industry. We focus on building systems that help individuals and organizations to have safe and secure digital presence by providing cutting edge technologies to our customers. We create products and services that ensure our customers security using data driven technologies to understand whether audio and video media is authentic or fake.
Our goal in this project is to build algorithms that can synthesize spoken audio by converting a speaker’s voice to another speaker’s voice with the end goal to detect if any spoken audio is pristine or fake.

## Data Description:
There are two datasets you can utilize in this project. Both datasets are publicly available sources.

TIMIT Dataset:
The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains a total of 6300 sentences, 10 sentences spoken by each of 630 speakers from 8 major dialect regions of the United States.
Dataset Link: https://github.com/philipperemy/timit

CommonVoice Dataset:
Common Voice is part of Mozilla's initiative to help teach machines how real people speak. Common Voice is a corpus of speech data read by users on the Common Voice website (https://commonvoice.mozilla.org/), and based upon text from a number of public domain sources like user submitted blog posts, old books, movies, and other public speech corpora. Its primary purpose is to enable the training and testing of automatic speech recognition (ASR) systems.
Dataset Link: https://commonvoice.mozilla.org/en/datasets

## Goal(s):
Build a machine learning system to detect if a spoken audio is synthetically generated or not. In order to achieve this, first, build a voice cloning system given a speaker’s spoken audio that clones the source speaker’s voice to the target speaker’s voice. Next, build a machine learning system which detects if any spoken audio is a natural speech or synthetically generated by machine.
For the voice cloning system (VC), you can utilize the TIMIT dataset as it consists of aligned text-audio data with various speakers. For the fake audio detection system (FAD) you can utilize the CommonVoice dataset as it consists of thousands of naturally spoken audio which could be used as golden spoken audio by humans as positive examples and creating negative examples using the voice cloning system as automatic data/label generator. Since the CommonVoice English dataset is large, you can use a subset of it by sampling the dataset.

## Methodology:
The system is composed by two different sub-system: the voice cloning system and the fake audio detection system. 
### Voice Cloning system:
1) TIMIT dataset is used to extract audio features and text transcriptions.
2) The pre-trained model xtts_v2 from Coqui TTS package are used for generating audio files cloning the speaker voice.
3) The audio files generated are transferred back to text using OpenAI Whisper.
4) The Word Error Rate (WER) respect to the original text on the test set is computed. WER is also calculated for each speaker.
5) The mean and standard deviation of WER is evaluated.
### Fake Audio Detection system:
1) Use the Voice Cloning system to generate fake audio files from the CommonVoice dataset.
2) Train and evaluate a binary CNN classifier using the original CommonVoice dataset and the fake audio samples created.

## Conclusions:
The final trained model was able to achieve 99% precision, recall and F1 score on the test set. In detail only one fake sample is misclassified as real and 23 real samples are classified as fake. The performance are exceptional for this particular case but bigger and complex dataset could require a more complex model. Also the method to create fake audio files could be improved with the fine-tuning of the pretrained Tacotron2 model or different model could be considered.


